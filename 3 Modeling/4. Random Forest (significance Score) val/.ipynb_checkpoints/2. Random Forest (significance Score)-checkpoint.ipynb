{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <b> <h1> Random Forest (Significance Score - Best N of Rois) </h1></b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Explanation about it: <h1>\n",
    "    <p style=\"font-weight: normal; font-size: 18px; text-align: justify;\"> \n",
    "        in this file the goal is find the mos significants areas for the model,\n",
    "        for this we used the random forest created in the lastone step of training, \n",
    "        in wich we have one randome Fores(.pkl) for each featur (area, thickness, volumen, MeanCurv), \n",
    "        whit all the features (148 for each subject composed for Rh and Lh. we used the attribute of\n",
    "        <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.feature_importances_\">   feature_importances.</a>, for know the significance of each feature at the 4 differentes models (RF).\n",
    "        You have to take in count that the best model of training  was arroud 72% of accuracy, so \n",
    "        we have to no that the sum of all the significances will be 1, but this one represent a 7x% of\n",
    "        accuracy of each model\n",
    "    </p>\n",
    "    <p style=\"font-weight: normal; font-size: 18px; text-align: justify;\">\n",
    "        we upgrade this part of our project for find the best number of most significant features for each model.\n",
    "        we can say that each features was modeled with the same number of n_clasificator inside the random forest\n",
    "    </p>\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "PATH_DATASETS = \"../../2_Data_preparation/2_Split_Raw_Datasets/output/\"\n",
    "PATH_PKL = \"../../3 Modeling/3  Random Forest ( All features) val/output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCsvs():\n",
    "    datasets = []\n",
    "    constant1 = 'X_'\n",
    "    constant2 = '_validate'\n",
    "    features = ['area', 'meancurv', 'thickness', 'volume']\n",
    "\n",
    "    for feature in features:\n",
    "        df = pd.read_csv(PATH_DATASETS + constant1 + feature + constant2 +'.csv', index_col=0)\n",
    "        datasets.append({'name': feature, 'data': df})\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readClf():\n",
    "    randomForests = []\n",
    "    constant1 = \"RandomForest (AllFeatures) \"\n",
    "    features = ['area', 'meancurv', 'thickness', 'volume']\n",
    "\n",
    "    for feature in features:\n",
    "        clf = joblib.load(PATH_PKL + constant1 + feature + '.pkl')\n",
    "        randomForests.append({'name': feature, 'data': clf})\n",
    "        \n",
    "    return randomForests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainRandomForest(data_x, data_y):\n",
    "    \"\"\" create a random forest classifier and train it\n",
    "    \n",
    "    Parameters:\n",
    "        data_x : pandas dataframe\n",
    "            a formatted dataframe that has the value for each ROI of the brain\n",
    "            evaluated by a feature (Area, Thickness, MeanCurv, Volumen) for \n",
    "            subjects the subjects that make up the kinf of dataset (training,\n",
    "            test, validation)\n",
    "        data_y : pandas dataframe\n",
    "            a formatted dataframe that has the classification(weak, strong) for\n",
    "            subjects the subjects that make up the kinf of dataset (training,\n",
    "            test, validation)\n",
    "            \n",
    "    Returns:\n",
    "        obb_score: float\n",
    "           accuracy of the model\n",
    "    \"\"\"\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=6000, random_state=0, n_jobs=-1, oob_score=True, verbose=True)\n",
    "    \"\"\"* n_estimators : The number of trees in the forest.\n",
    "        * n_jobs = -1 : use all the processors\n",
    "        * oob_score = true: Whether to use out-of-bag samples to estimate the generalization accuracy.\n",
    "        * verbose  = Controls the verbosity when fitting and predicting.\"\"\"\n",
    "    \n",
    "    oob_score = clf.fit(data_x, data_y['class'].values)    # Train the classifier\n",
    "    \n",
    "    return oob_score.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_number_of_Rois(significance,\n",
    "                                   data_x,\n",
    "                                   data_y, \n",
    "                                   step = 5):\n",
    "    \"\"\"\n",
    "    A Function used to find the best number of rois for train a RF mondel.\n",
    "\n",
    "    Parameters:\n",
    "        significance : pandas dataframe\n",
    "            a formatted dataframe that has the ROIs name and their significance\n",
    "            ordered from most significant to less significant \n",
    "        data_x : pandas dataframe\n",
    "            a formatted dataframe that has the value for each ROI of the brain\n",
    "            evaluated by a feature (Area, Thickness, MeanCurv, Volumen) for \n",
    "            subjects the subjects that make up the kinf of dataset (training,\n",
    "            test, validation)\n",
    "        data_y : pandas dataframe\n",
    "            a formatted dataframe that has the classification(weak, strong) for\n",
    "            subjects the subjects that make up the kinf of dataset (training,\n",
    "            test, validation)\n",
    "        step : int\n",
    "            the number of features that make up the step of evalutio (default 5)\n",
    "            \n",
    "    Returns:\n",
    "        df_obb_score: pandas dataframe\n",
    "            a formatted dataframe that has the number (quantity) of features \n",
    "            and the obb_score\n",
    "    \"\"\"\n",
    "    \n",
    "    df_obb_results = pd.DataFrame(columns=['quantity', 'obb_score']) \n",
    "    df_obb_results.set_index('quantity', inplace = True)\n",
    "    \n",
    "    number_of_Rois = step    # Initial number of feature for train the RF\n",
    "    delta = step\n",
    "    size_data = len(significance.index)\n",
    "    \n",
    "    conter = 0\n",
    "    \n",
    "    while number_of_Rois <= size_data:\n",
    "        \n",
    "        print(\"number_of_Rois: \" + str(number_of_Rois) + '\\n')\n",
    "        \n",
    "        acumulative_name_rois = significance[:number_of_Rois]    # take in step of @step Rois\n",
    "        #print(acumulative_name_rois)\n",
    "        \n",
    "        acumulative_name_rois = acumulative_name_rois.index.values    # take just the names  \n",
    "        #print(acumulative_name_rois)\n",
    "        \n",
    "        data_x_train = data_x[acumulative_name_rois].copy()\n",
    "        #print(data_x_train)\n",
    "        \n",
    "        obb_score = TrainRandomForest(data_x_train, data_y)\n",
    "        \n",
    "        df_obb_results.at[number_of_Rois] = obb_score\n",
    "        \n",
    "        if((number_of_Rois + delta) >= size_data) and (conter == 0):\n",
    "            number_of_Rois = size_data\n",
    "            conter += 1\n",
    "        elif(conter > 0):\n",
    "            number_of_Rois = size_data + 10\n",
    "        else:\n",
    "            number_of_Rois += delta\n",
    "        \n",
    "    return df_obb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    " def plot_graf(x, y = 0, \n",
    "               line_type = \"-o\",  \n",
    "               title = \"PLOT\", \n",
    "               x_legend = \"X\", \n",
    "               y_legend = \"Y\",\n",
    "               width = 15,\n",
    "               heigh = 10):\n",
    "        \"\"\"\n",
    "        A Function used to find the best number of rois for train a RF mondel.\n",
    "\n",
    "        Parameters:\n",
    "            x : array\n",
    "                values of x axe \n",
    "            y : array\n",
    "                values of y axe \n",
    "            line_type: str\n",
    "                str that describes the line for the plot\n",
    "            title: str\n",
    "                str that describes the title\n",
    "            x_legend: str\n",
    "                legend of the x axe\n",
    "            y_legend: str\n",
    "                legend of the y axe\n",
    "            width:int\n",
    "                width of the plot\n",
    "            heigh:int\n",
    "                heigh of the plot\n",
    "        \"\"\"\n",
    "        \n",
    "        plt.figure(figsize=(width,heigh), dpi=100)\n",
    "          \n",
    "        if type(y) == int :\n",
    "            plt.plot(x,line_type)\n",
    "        else:\n",
    "            plt.plot(x,y,line_type)\n",
    "            \n",
    "            # 1. Adjust x axis Ticks\n",
    "            plt.xticks(ticks = x, fontsize=12, rotation=30, ha='center', va='top')\n",
    "\n",
    "            # 2. Tick Parameters\n",
    "            plt.tick_params(axis='both',bottom=True, top=True, left=True, right=True, direction='in', which='major', grid_color='blue')\n",
    "\n",
    "        plt.grid(linestyle='--', linewidth=0.7, alpha=0.1)\n",
    "        plt.title(title, fontsize = 14)\n",
    "        plt.xlabel(x_legend, fontsize = 20)\n",
    "        plt.ylabel(y_legend, fontsize = 20)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_result_obb_score(df):\n",
    "    arr = df['obb_score'].values\n",
    "    arr = np.array(arr)\n",
    "    \n",
    "    position = np.where(arr == np.amax(arr))\n",
    "    result = df.index.values[position]\n",
    "\n",
    "    return result[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(338, 148)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_tr = readCsvs()\n",
    "df_X_tr[0]['data'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(338, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_tr = pd.read_csv(PATH_DATASETS + 'Y_validate.csv')\n",
    "df_y_tr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  Identify the most significants features from R.A. classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = readClf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = []\n",
    "\n",
    "for feature, clf in zip(df_X_tr, clfs):\n",
    "    \n",
    "    data = feature['data']\n",
    "    name = feature['name']\n",
    "    Rf = clf['data']\n",
    "    \n",
    "    #not is a obb error is how much this variable apports to the model \n",
    "    df_features = pd.DataFrame(columns=['Name', 'Significance']) \n",
    "    df_features.set_index('Name', inplace = True)\n",
    "    #df_features.head()\n",
    "\n",
    "    for column in zip(data.columns.values, Rf.feature_importances_):\n",
    "        #print(column)\n",
    "        df_features.at[column[0]] = column[1]\n",
    "    \n",
    "    #print(df_features)\n",
    "    #Total = df_features['Significance'].sum()\n",
    "    #print (\"for: \" + name + \" : \" + str(Total))\n",
    "    \n",
    "    tables.append({'name' : name, 'data' : df_features})\n",
    "\n",
    "    \n",
    "#print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_number_of_features = pd.DataFrame(columns=['Name', 'quantity']) \n",
    "df_number_of_features.set_index('Name', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acumulative_significance(significances):\n",
    "    acumulative_significance = []\n",
    "    acumulative_value = 0\n",
    "    \n",
    "    for significance in significances:\n",
    "        acumulative_value += significance\n",
    "        acumulative_significance.append(acumulative_value)\n",
    "    \n",
    "    #print(acumulative_significance)\n",
    "    return acumulative_significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_Rois: 5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 6000 out of 6000 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_Rois: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 6000 out of 6000 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number_of_Rois: 15\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed:    2.8s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-84b1402b36f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#print(acacumulative_significance)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mobb_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_number_of_Rois\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_y_tr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;31m#print(obb_scores['obb_score'].values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-3920dde283ca>\u001b[0m in \u001b[0;36mbest_number_of_Rois\u001b[0;34m(significance, data_x, data_y, step)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m#print(data_x_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mobb_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainRandomForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mdf_obb_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumber_of_Rois\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobb_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-52fdbf6972f1>\u001b[0m in \u001b[0;36mTrainRandomForest\u001b[0;34m(data_x, data_y)\u001b[0m\n\u001b[1;32m     24\u001b[0m         * verbose  = Controls the verbosity when fitting and predicting.\"\"\"\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0moob_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m    \u001b[0;31m# Train the classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moob_score\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moob_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 333\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "conter = 0\n",
    "for feature, df_features in zip(df_X_tr, tables):\n",
    "    \n",
    "    data_feature = feature['data']\n",
    "    data = df_features['data']\n",
    "    name = df_features['name']\n",
    "    \n",
    "    data.sort_values(\"Significance\", axis= 0, ascending = False, inplace = True)\n",
    "    #print(data.head())\n",
    "    \n",
    "    vector = data['Significance'].values\n",
    "    \n",
    "    acumulative_significance = calc_acumulative_significance(vector)\n",
    "    #print(acacumulative_significance)\n",
    "    \n",
    "    obb_scores = best_number_of_Rois(data, data_feature, df_y_tr)\n",
    "    #print(obb_scores['obb_score'].values)\n",
    "    \n",
    "    plot_graf(data['Significance'].values,\n",
    "              0,\n",
    "              \"-o\", \n",
    "              'Significance for each ROI: '+ name, \n",
    "              \"Region\", \n",
    "              \"Significance\")\n",
    "    \n",
    "    plot_graf(acumulative_significance,\n",
    "              0,\n",
    "              \"-mo\", \n",
    "              'Significance acumulative for: '+ name, \n",
    "              \"Number of region\", \n",
    "              \"Significance\")\n",
    "    \n",
    "    plot_graf(obb_scores.index.values, \n",
    "              obb_scores['obb_score'].values, \n",
    "              \"-ro\", \n",
    "              'Obb Score for number of most significant rois ' + name, \n",
    "              \"number of fetures\", \n",
    "              \"OBB score\")\n",
    "    \n",
    "    data.to_csv(\"output/Random Forest (AllFeatures - Significance) \"+ name +\".csv\")\n",
    "    \n",
    "    best_number_of_rois = max_result_obb_score(obb_scores)\n",
    "    print(\"this is the best number for \" + str(name) +\": \" + str(best_number_of_rois) + \"\\n\")\n",
    "    \n",
    "    df_number_of_features.at[name] = best_number_of_rois\n",
    "    \n",
    "    # in this part we select the best number of rois for each model and we store it in a csv file \n",
    "    tables[conter]['data'][:int(best_number_of_rois)].to_csv(\"output/Random Forest (AllFeatures - Significance - \"\n",
    "                                                        + str(best_number_of_rois) + \")\" \n",
    "                                                        + tables[conter]['name']+\".csv\")\n",
    "    conter += 1\n",
    "    \n",
    "df_number_of_features.to_csv(\"output/Random Forest Best Number Of Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
